{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.scrape_insta\n",
    "import src.clean as clean\n",
    "%autoreload\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualdf = pd.read_csv('soft_content.txt', sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls = list(qualdf.url.unique())\n",
    "pickle_in2 = open(\"quant_data.pkl\",\"rb\")\n",
    "quant_df = pickle.load(pickle_in2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#postdf2 = clean.clean_fresh_instagram_post_data(postdf)\n",
    "postdf2_url_index = postdf2.set_index('url', drop=False)\n",
    "qualdf_url_index = qualdf.set_index('url')\n",
    "\n",
    "combined = pd.concat([postdf2_url_index, qualdf_url_index], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_combined(combined):\n",
    "    combined = combined.drop(labels=['date_num', 'day','date','url','taken_at','num_posts','year','people_tagged','number_of_comments','hashtags','comments','commenters','caption','num_people'], axis=1)\n",
    "    combined['male'] = combined['is_male'] == 1\n",
    "    combined['female'] = combined['is_male'] == 0\n",
    "    combined['mixed_gender'] = combined['is_male'] == 2\n",
    "    combined['bikini'] = combined['bikini/apparel'] == 'b'\n",
    "    combined['apparel'] = combined['bikini/apparel'] == 'a'\n",
    "    combined['biki+apparel'] = combined['bikini/apparel'] == 'c'\n",
    "    combined['no_product'] = combined['bikini/apparel'] == 'd'\n",
    "    combined=combined.drop(['bikini/apparel','is_male'], axis=1)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined2=clean_combined(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 40)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_comb = combined2['number_of_likes']\n",
    "X_comb = combined2.drop(['number_of_likes'], axis=1)\n",
    "\n",
    "X_comb_train, X_comb_test, y_comb_train, y_comb_test = train_test_split(X_comb.as_matrix(), y_comb.as_matrix(), test_size= .15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=1,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(learning_rate=0.1, loss='ls', n_estimators=100, random_state=1)\n",
    "\n",
    "gbr.fit(X_comb_train,y_comb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH COMBINED DATA\n",
      "mse = 6133.64\n",
      "rse = 78.32\n"
     ]
    }
   ],
   "source": [
    "y_hat_comb = gbr.predict(X_comb_test)\n",
    "mse_comb = mean_squared_error(y_comb_test,y_hat_comb)\n",
    "rse_comb = np.sqrt(mse_comb)\n",
    "print(\"WITH COMBINED DATA\")\n",
    "print('mse = {}'.format(round(mse_comb,2)))\n",
    "print('rse = {}'.format(round(rse_comb,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats2 = gbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = gbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09817831, 0.21603   , 0.11826235, 0.02365636, 0.00401511,\n",
       "       0.04028335, 0.02482832, 0.03720151, 0.01378616, 0.0147315 ,\n",
       "       0.02268171, 0.00207635, 0.02618405, 0.00210607, 0.00043331,\n",
       "       0.01474979, 0.01652931, 0.05996796, 0.03396877, 0.03726308,\n",
       "       0.02046913, 0.01677129, 0.00022131, 0.021929  , 0.0388441 ,\n",
       "       0.00806883, 0.03688874, 0.01474272, 0.01357673, 0.02155476])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people_tagged : 0.0982 | 0.1124\n",
      "month : 0.216 | 0.2205\n",
      "hour : 0.1183 | 0.1199\n",
      "DOW_0 : 0.0237 | 0.0013\n",
      "DOW_1 : 0.004 | 0.0327\n",
      "DOW_2 : 0.0403 | 0.0522\n",
      "DOW_3 : 0.0248 | 0.0345\n",
      "DOW_4 : 0.0372 | 0.0296\n",
      "DOW_5 : 0.0138 | 0.0339\n",
      "DOW_6 : 0.0147 | 0.0322\n",
      "faces_visible : 0.0227 | 0.0305\n",
      "sale : 0.0021 | 0.0\n",
      "edited : 0.0262 | 0.0173\n",
      "butt_pic : 0.0021 | 0.0042\n",
      "ocean : 0.0004 | 0.0094\n",
      "skate : 0.0147 | 0.0343\n",
      "drift_content : 0.0165 | 0.0216\n",
      "product_shot : 0.06 | 0.0125\n",
      "lifestyle : 0.034 | 0.0239\n",
      "in_shop : 0.0373 | 0.0313\n",
      "pro\\model : 0.0205 | 0.0207\n",
      "in_nature : 0.0168 | 0.0088\n",
      "surf : 0.0002 | 0.0048\n",
      "male : 0.0219 | 0.0271\n",
      "female : 0.0388 | 0.0103\n",
      "mixed_gender : 0.0081 | 0.0259\n",
      "bikini : 0.0369 | 0.0141\n",
      "apparel : 0.0147 | 0.021\n",
      "biki+apparel : 0.0136 | 0.0086\n",
      "no_product : 0.0216 | 0.0046\n"
     ]
    }
   ],
   "source": [
    "for name, imp, imp2 in zip(list(X_comb.columns),feats, feats2):\n",
    "    print (\"{} : {} | {}\".format(name, round(imp,4),round(imp2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just with quantitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 24)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postdf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_quan = postdf2['number_of_likes']\n",
    "X_quan = postdf2[['DOW_0','DOW_1','DOW_2','DOW_3','DOW_4','DOW_5','DOW_6','hour','month','num_people_tagged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=1,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_quan_train, X_quan_test, y_quan_train, y_quan_test = train_test_split(X_quan.as_matrix(), y_quan.as_matrix(), test_size= .15)\n",
    "\n",
    "gbr= GradientBoostingRegressor(learning_rate=0.1, loss='ls', n_estimators=100)\n",
    "gbr.fit(X_quan_train,y_quan_train)\n",
    "\n",
    "y_hat_quan = gbr.predict(X_quan_test)\n",
    "mse = mean_squared_error(y_quan_test, y_hat_quan)\n",
    "rse = np.sqrt(mse)\n",
    "print(\"WITH QUANTITATIVE DATA\")\n",
    "print('mse = {}'.format(round(mse,2)))\n",
    "print('rse = {}'.format(round(rse,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rest_insta = pd.read_csv('data/data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rest_insta2 = clean.clean_instagram_post_data(rest_insta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_insta2.iloc[-1,:].year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rest_insta[rest_insta['year']>=2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtag_corpus = list(postdf2.hashtags)\n",
    "\n",
    "hashtag_corpus2 = take_out_hash(hashtag_corpus)\n",
    "\n",
    "hashtag_corpus3=[' '.join(hashtag_corpus2[i]) for i in range(len(hashtag_corpus2))]\n",
    "\n",
    "tfidf_hash = TfidfVectorizer(input='content')\n",
    "\n",
    "tfidf_hash.fit(hashtag_corpus3)\n",
    "hash_mat =tfidf_hash.transform(hashtag_corpus3)\n",
    "tfidf_hash_mat = pd.SparseDataFrame(hash_mat, index = postdf2.index).to_dense().fillna(0)\n",
    "\n",
    "tfidf_hash_mat.shape\n",
    "\n",
    "def take_out_sign(hashtag_corpus, sign='\\#'):\n",
    "    new_corp=[]\n",
    "    for tags in hashtag_corpus:\n",
    "        just_words = []\n",
    "        for tag in tags:\n",
    "            just_words.append(re.sub(sign,'',tag))\n",
    "        new_corp.append(just_words)\n",
    "    return new_corp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_out_sign2(caption_corpus, sign='\\#'):\n",
    "    new_corp=[]\n",
    "    for string in caption_corpus:\n",
    "        string=re.sub(sign,'',string)\n",
    "        new_corp.append(string)\n",
    "    return new_corp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_corpus  ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_corpus = list(postdf2.caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_corpus2 = take_out_sign2(caption_corpus)\n",
    "caption_corpus2 = take_out_sign2(caption_corpus2, sign= '\\@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(input='content', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(caption_corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap_mat =tfidf.transform(caption_corpus2)\n",
    "\n",
    "tfidf_mat = pd.SparseDataFrame(cap_mat, index = postdf2.index).to_dense().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 818)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined3 =pd.concat([combined2, tfidf_mat2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_mat2 = tfidf_mat.set_index(combined2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = combined4['number_of_likes']\n",
    "X = combined4.drop(['number_of_likes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH QUANTITATIVE DATA\n",
      "mse = 2392.86\n",
      "rse = 48.92\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.as_matrix(), y.as_matrix(), test_size= .15)\n",
    "\n",
    "GradientBoostingRegressor(learning_rate=0.001, loss='ls', n_estimators=10)\n",
    "gbr.fit(X_train,y_train)\n",
    "\n",
    "y_hat = gbr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_hat)\n",
    "rse = np.sqrt(mse)\n",
    "print(\"WITH QUANTITATIVE DATA\")\n",
    "print('mse = {}'.format(round(mse,2)))\n",
    "print('rse = {}'.format(round(rse,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_hash_mat2 = tfidf_hash_mat.set_index(combined2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined4 = pd.concat([combined2, tfidf_hash_mat2], axis=1)\n",
    "combined5 = pd.concat([combined3, tfidf_hash_mat2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 1073)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>commenters</th>\n",
       "      <th>comments</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>number_of_likes</th>\n",
       "      <th>taken_at</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>people_tagged</th>\n",
       "      <th>...</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>date_num</th>\n",
       "      <th>num_posts</th>\n",
       "      <th>DOW_1</th>\n",
       "      <th>DOW_2</th>\n",
       "      <th>DOW_3</th>\n",
       "      <th>DOW_4</th>\n",
       "      <th>DOW_5</th>\n",
       "      <th>DOW_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHOP LOCAL 🌈  @pioneersboardshop  @cinnamonrai...</td>\n",
       "      <td>[nolongersauced, thedriftcollective]</td>\n",
       "      <td>[I &lt;3 bethel skatepark, .\\n.\\n.\\n.\\n.\\n#summer...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1515166569</td>\n",
       "      <td>http://www.instagram.com/p/BdkrH7uHkpr/?taken-...</td>\n",
       "      <td>2018-01-05 15:36:09</td>\n",
       "      <td>[nolongersauced, pioneersboardshop, cinnamonra...</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>20180105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snow day 🍻 Shop will reopen tomorrow at noon! ...</td>\n",
       "      <td>[wyndhamvacationrentals, demetriusortakales, h...</td>\n",
       "      <td>[We'd love to feature your photo!  Can we shar...</td>\n",
       "      <td>[#summersunselection, #createexploretakeover, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>468</td>\n",
       "      <td>1515078603</td>\n",
       "      <td>http://www.instagram.com/p/BdiDVyynAdH/?taken-...</td>\n",
       "      <td>2018-01-04 15:10:03</td>\n",
       "      <td>[rhlockhart, thedriftcollective, rhlockhart]</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>20180104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shop open again tomorrow! 🛷🌴 Brave the cold + ...</td>\n",
       "      <td>[johnnyoconnor, zynenwartel, thedriftcollectiv...</td>\n",
       "      <td>[I gotta come try this on, 👌👌, @johnnyoconnor ...</td>\n",
       "      <td>[#summersunselection, #urbanstyle, #modernstyl...</td>\n",
       "      <td>6</td>\n",
       "      <td>244</td>\n",
       "      <td>1514933720</td>\n",
       "      <td>http://www.instagram.com/p/Bddu_4Vn5pM/?taken-...</td>\n",
       "      <td>2018-01-02 22:55:20</td>\n",
       "      <td>[thedriftcollective]</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>20180102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merry Christmas Eve ⭐️ Come celebrate and fini...</td>\n",
       "      <td>[micky_kimm, theprosperitygirl]</td>\n",
       "      <td>[😊😄, 😊😊✌...]</td>\n",
       "      <td>[#vintagechristmas, #merrychristmaseve, #summe...</td>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "      <td>1514130168</td>\n",
       "      <td>http://www.instagram.com/p/BdFyWJOnkVz/?taken-...</td>\n",
       "      <td>2017-12-24 15:42:48</td>\n",
       "      <td>[elisabettalockhart, sea__soul, slimaarons, sl...</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>20171224</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🔥🔥🔥 You deserve to dress one of a kind. Our di...</td>\n",
       "      <td>[hdcostinyamoney, veilleuxkristen, westvillage...</td>\n",
       "      <td>[Love it🤗, @hdcostinyamoney @juliiivanegas fin...</td>\n",
       "      <td>[#shopsustainable, #summersunselection, #urban...</td>\n",
       "      <td>9</td>\n",
       "      <td>296</td>\n",
       "      <td>1514059594</td>\n",
       "      <td>http://www.instagram.com/p/BdDrvIOn_nk/?taken-...</td>\n",
       "      <td>2017-12-23 20:06:34</td>\n",
       "      <td>[hdcostinyamoney, veilleuxkristen, thedriftcol...</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>20171223</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0  SHOP LOCAL 🌈  @pioneersboardshop  @cinnamonrai...   \n",
       "1  Snow day 🍻 Shop will reopen tomorrow at noon! ...   \n",
       "2  Shop open again tomorrow! 🛷🌴 Brave the cold + ...   \n",
       "3  Merry Christmas Eve ⭐️ Come celebrate and fini...   \n",
       "4  🔥🔥🔥 You deserve to dress one of a kind. Our di...   \n",
       "\n",
       "                                          commenters  \\\n",
       "0               [nolongersauced, thedriftcollective]   \n",
       "1  [wyndhamvacationrentals, demetriusortakales, h...   \n",
       "2  [johnnyoconnor, zynenwartel, thedriftcollectiv...   \n",
       "3                    [micky_kimm, theprosperitygirl]   \n",
       "4  [hdcostinyamoney, veilleuxkristen, westvillage...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  [I <3 bethel skatepark, .\\n.\\n.\\n.\\n.\\n#summer...   \n",
       "1  [We'd love to feature your photo!  Can we shar...   \n",
       "2  [I gotta come try this on, 👌👌, @johnnyoconnor ...   \n",
       "3                                       [😊😄, 😊😊✌...]   \n",
       "4  [Love it🤗, @hdcostinyamoney @juliiivanegas fin...   \n",
       "\n",
       "                                            hashtags  number_of_comments  \\\n",
       "0                                                 []                   2   \n",
       "1  [#summersunselection, #createexploretakeover, ...                   3   \n",
       "2  [#summersunselection, #urbanstyle, #modernstyl...                   6   \n",
       "3  [#vintagechristmas, #merrychristmaseve, #summe...                   2   \n",
       "4  [#shopsustainable, #summersunselection, #urban...                   9   \n",
       "\n",
       "   number_of_likes    taken_at  \\\n",
       "0              300  1515166569   \n",
       "1              468  1515078603   \n",
       "2              244  1514933720   \n",
       "3              258  1514130168   \n",
       "4              296  1514059594   \n",
       "\n",
       "                                                 url                date  \\\n",
       "0  http://www.instagram.com/p/BdkrH7uHkpr/?taken-... 2018-01-05 15:36:09   \n",
       "1  http://www.instagram.com/p/BdiDVyynAdH/?taken-... 2018-01-04 15:10:03   \n",
       "2  http://www.instagram.com/p/Bddu_4Vn5pM/?taken-... 2018-01-02 22:55:20   \n",
       "3  http://www.instagram.com/p/BdFyWJOnkVz/?taken-... 2017-12-24 15:42:48   \n",
       "4  http://www.instagram.com/p/BdDrvIOn_nk/?taken-... 2017-12-23 20:06:34   \n",
       "\n",
       "                                       people_tagged  ...    day  hour  \\\n",
       "0  [nolongersauced, pioneersboardshop, cinnamonra...  ...      5    15   \n",
       "1       [rhlockhart, thedriftcollective, rhlockhart]  ...      4    15   \n",
       "2                               [thedriftcollective]  ...      2    22   \n",
       "3  [elisabettalockhart, sea__soul, slimaarons, sl...  ...     24    15   \n",
       "4  [hdcostinyamoney, veilleuxkristen, thedriftcol...  ...     23    20   \n",
       "\n",
       "   date_num  num_posts  DOW_1  DOW_2  DOW_3  DOW_4  DOW_5  DOW_6  \n",
       "0  20180105          1      0      0      0      1      0      0  \n",
       "1  20180104          1      0      0      1      0      0      0  \n",
       "2  20180102          1      1      0      0      0      0      0  \n",
       "3  20171224          1      0      0      0      0      0      1  \n",
       "4  20171223          1      0      0      0      0      1      0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_insta2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_quant_with_dup = pd.concat([rest_insta2, postdf2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_quant_with_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_quant = all_quant_with_dup.drop_duplicates(subset='caption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open(\"quant_data.pkl\",\"wb\")\n",
    "pickle.dump(all_quant, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all2017on = all_quant[all_quant['year']>=2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all2017on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppl_tagged = list(all_quant.people_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppl_ever_tagged = {}\n",
    "for ppl in ppl_tagged:\n",
    "    for per in ppl:\n",
    "        if per not in ppl_ever_tagged:\n",
    "            ppl_ever_tagged[per]=1\n",
    "        else:    \n",
    "            ppl_ever_tagged[per]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppl_ever_tagged;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle_out = open(\"ppl_ever_tagged.pkl\",\"wb\")\n",
    "pickle.dump(ppl_ever_tagged, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_in = open(\"ppl_ever_tagged.pkl\",\"rb\")\n",
    "example_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_dict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serious_reps=[]\n",
    "mid_reps = []\n",
    "lesser_reps = []\n",
    "for key, val in ppl_ever_tagged.items():\n",
    "    if val >= 10:\n",
    "        serious_reps.append(key)\n",
    "    if val >= 4 and val < 6:\n",
    "        lesser_reps.append(key)\n",
    "    if val >= 6 and val <10:\n",
    "        mid_reps.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(lesser_reps))\n",
    "print(len(mid_reps))\n",
    "print(len(serious_reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = combined4['number_of_likes']\n",
    "X = combined4.drop(['number_of_likes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-48.480377205046416\n",
      "[ -38.15759618  -41.46070029   -7.06369215  -50.27301336  -62.2982722\n",
      "  -91.69993866  -18.91128562  -44.17522856  -51.58734248  -16.2278911\n",
      "  -75.66074756  -83.00390288  -45.78961711  -90.48344108  -48.3360088\n",
      "  -27.46482184  -54.77182226  -43.95735829  -66.76219801  -36.21908022\n",
      "  -27.44591783  -55.99077238  -12.21049814  -21.17192359  -66.35742076\n",
      "  -57.76466755  -21.8554863   -22.1195746   -48.25592832  -15.11909521\n",
      "  -50.94315015  -36.71826243  -64.5390411   -21.46128815  -83.65685558\n",
      "  -65.09989994  -46.60912983  -82.65519532  -24.50847012 -120.42855226]\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(learning_rate=0.01, loss='ls', min_samples_split=4, n_estimators=600, max_depth=2)\n",
    "scores = cross_val_score(gbr, X, y,cv=40, scoring= 'neg_mean_absolute_error')\n",
    "print(scores.mean())\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_=gbr.fit(X.as_matrix(),y.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people_tagged : 0.043\n",
      "month : 0.02\n",
      "hour : 0.032\n",
      "in_shop : 0.042\n",
      "pro\\model : 0.042\n",
      "no_product : 0.032\n",
      "16 : 0.017\n",
      "48 : 0.022\n",
      "58 : 0.021\n",
      "59 : 0.023\n",
      "62 : 0.02\n",
      "71 : 0.034\n",
      "84 : 0.022\n",
      "88 : 0.053\n",
      "91 : 0.015\n",
      "102 : 0.034\n",
      "110 : 0.024\n",
      "111 : 0.076\n",
      "115 : 0.046\n",
      "116 : 0.016\n",
      "131 : 0.047\n",
      "150 : 0.018\n",
      "158 : 0.034\n",
      "186 : 0.023\n",
      "203 : 0.025\n",
      "205 : 0.044\n",
      "220 : 0.025\n",
      "223 : 0.017\n"
     ]
    }
   ],
   "source": [
    "for name, imp in zip(X.columns,gbr.feature_importances_):\n",
    "    if imp > .015:\n",
    "        print('{} : {}'.format(name, round(imp,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105 entries, 0 to 104\n",
      "Data columns (total 24 columns):\n",
      "caption               105 non-null object\n",
      "commenters            105 non-null object\n",
      "comments              105 non-null object\n",
      "hashtags              105 non-null object\n",
      "number_of_comments    105 non-null int64\n",
      "number_of_likes       105 non-null int64\n",
      "people_tagged         105 non-null object\n",
      "taken_at              105 non-null int64\n",
      "url                   105 non-null object\n",
      "date                  105 non-null datetime64[ns]\n",
      "num_people_tagged     105 non-null int64\n",
      "year                  105 non-null int64\n",
      "month                 105 non-null int64\n",
      "day                   105 non-null int64\n",
      "hour                  105 non-null int64\n",
      "date_num              105 non-null int64\n",
      "num_posts             105 non-null int64\n",
      "DOW_0                 105 non-null uint8\n",
      "DOW_1                 105 non-null uint8\n",
      "DOW_2                 105 non-null uint8\n",
      "DOW_3                 105 non-null uint8\n",
      "DOW_4                 105 non-null uint8\n",
      "DOW_5                 105 non-null uint8\n",
      "DOW_6                 105 non-null uint8\n",
      "dtypes: datetime64[ns](1), int64(10), object(6), uint8(7)\n",
      "memory usage: 14.7+ KB\n"
     ]
    }
   ],
   "source": [
    "postdf2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop=['number_of_likes','caption','commenters','comments','date', 'date_num','hashtags', 'num_posts', 'number_of_comments','people_tagged','taken_at', 'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time lag of insta to shopsales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
